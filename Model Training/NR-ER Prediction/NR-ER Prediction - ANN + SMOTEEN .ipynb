{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "379ef657-22bf-443d-9090-62f26ff39a88",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7965eacb-0780-4710-8294-15f9ef285c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57194a3e-498f-45c5-8142-9ed414fc1269",
   "metadata": {},
   "source": [
    "# Read-In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c85950a-adc2-46fc-affc-e6ab16c3af99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mol_id</th>\n",
       "      <th>MolecularWeight</th>\n",
       "      <th>LogP</th>\n",
       "      <th>TPSA</th>\n",
       "      <th>HBDonors</th>\n",
       "      <th>HBAcceptors</th>\n",
       "      <th>RotatableBonds</th>\n",
       "      <th>FractionCSP3</th>\n",
       "      <th>HeavyAtoms</th>\n",
       "      <th>RingCount</th>\n",
       "      <th>...</th>\n",
       "      <th>NR-AhR</th>\n",
       "      <th>NR-Aromatase</th>\n",
       "      <th>NR-ER</th>\n",
       "      <th>NR-ER-LBD</th>\n",
       "      <th>NR-PPAR-gamma</th>\n",
       "      <th>SR-ARE</th>\n",
       "      <th>SR-ATAD5</th>\n",
       "      <th>SR-HSE</th>\n",
       "      <th>SR-MMP</th>\n",
       "      <th>SR-p53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOX3021</td>\n",
       "      <td>258.324</td>\n",
       "      <td>1.34240</td>\n",
       "      <td>82.28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOX3020</td>\n",
       "      <td>204.229</td>\n",
       "      <td>1.29940</td>\n",
       "      <td>49.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOX3024</td>\n",
       "      <td>288.475</td>\n",
       "      <td>5.09030</td>\n",
       "      <td>20.23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TOX3027</td>\n",
       "      <td>276.424</td>\n",
       "      <td>3.75244</td>\n",
       "      <td>32.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOX20800</td>\n",
       "      <td>206.027</td>\n",
       "      <td>-0.99220</td>\n",
       "      <td>135.29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mol_id  MolecularWeight     LogP    TPSA  HBDonors  HBAcceptors  \\\n",
       "0   TOX3021          258.324  1.34240   82.28       1.0          5.0   \n",
       "1   TOX3020          204.229  1.29940   49.41       1.0          2.0   \n",
       "2   TOX3024          288.475  5.09030   20.23       1.0          1.0   \n",
       "3   TOX3027          276.424  3.75244   32.34       1.0          2.0   \n",
       "4  TOX20800          206.027 -0.99220  135.29       5.0          3.0   \n",
       "\n",
       "   RotatableBonds  FractionCSP3  HeavyAtoms  RingCount  ...  NR-AhR  \\\n",
       "0             3.0      0.222222        16.0        2.0  ...       1   \n",
       "1             2.0      0.272727        15.0        2.0  ...       0   \n",
       "2             1.0      0.900000        21.0        4.0  ...       0   \n",
       "3             7.0      0.588235        20.0        1.0  ...       0   \n",
       "4             2.0      1.000000        11.0        0.0  ...       0   \n",
       "\n",
       "   NR-Aromatase  NR-ER  NR-ER-LBD  NR-PPAR-gamma  SR-ARE  SR-ATAD5  SR-HSE  \\\n",
       "0             0      0          0              0       1         0       0   \n",
       "1             0      0          0              0       0         0       0   \n",
       "2             0      0          0              0       0         0       0   \n",
       "3             0      0          0              0       0         0       0   \n",
       "4             0      0          0              0       0         0       0   \n",
       "\n",
       "   SR-MMP  SR-p53  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "2       0       0  \n",
       "3       0       0  \n",
       "4       0       0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../DATA/filled_toxicity_df.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df124ef-e3d0-40ce-bd27-75a8d892fcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MolecularWeight</th>\n",
       "      <th>LogP</th>\n",
       "      <th>TPSA</th>\n",
       "      <th>HBDonors</th>\n",
       "      <th>HBAcceptors</th>\n",
       "      <th>RotatableBonds</th>\n",
       "      <th>FractionCSP3</th>\n",
       "      <th>HeavyAtoms</th>\n",
       "      <th>RingCount</th>\n",
       "      <th>AromaticProportion</th>\n",
       "      <th>...</th>\n",
       "      <th>NR-AhR</th>\n",
       "      <th>NR-Aromatase</th>\n",
       "      <th>NR-ER</th>\n",
       "      <th>NR-ER-LBD</th>\n",
       "      <th>NR-PPAR-gamma</th>\n",
       "      <th>SR-ARE</th>\n",
       "      <th>SR-ATAD5</th>\n",
       "      <th>SR-HSE</th>\n",
       "      <th>SR-MMP</th>\n",
       "      <th>SR-p53</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mol_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TOX3021</th>\n",
       "      <td>258.324</td>\n",
       "      <td>1.34240</td>\n",
       "      <td>82.28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOX3020</th>\n",
       "      <td>204.229</td>\n",
       "      <td>1.29940</td>\n",
       "      <td>49.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOX3024</th>\n",
       "      <td>288.475</td>\n",
       "      <td>5.09030</td>\n",
       "      <td>20.23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOX3027</th>\n",
       "      <td>276.424</td>\n",
       "      <td>3.75244</td>\n",
       "      <td>32.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOX20800</th>\n",
       "      <td>206.027</td>\n",
       "      <td>-0.99220</td>\n",
       "      <td>135.29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          MolecularWeight     LogP    TPSA  HBDonors  HBAcceptors  \\\n",
       "mol_id                                                              \n",
       "TOX3021           258.324  1.34240   82.28       1.0          5.0   \n",
       "TOX3020           204.229  1.29940   49.41       1.0          2.0   \n",
       "TOX3024           288.475  5.09030   20.23       1.0          1.0   \n",
       "TOX3027           276.424  3.75244   32.34       1.0          2.0   \n",
       "TOX20800          206.027 -0.99220  135.29       5.0          3.0   \n",
       "\n",
       "          RotatableBonds  FractionCSP3  HeavyAtoms  RingCount  \\\n",
       "mol_id                                                          \n",
       "TOX3021              3.0      0.222222        16.0        2.0   \n",
       "TOX3020              2.0      0.272727        15.0        2.0   \n",
       "TOX3024              1.0      0.900000        21.0        4.0   \n",
       "TOX3027              7.0      0.588235        20.0        1.0   \n",
       "TOX20800             2.0      1.000000        11.0        0.0   \n",
       "\n",
       "          AromaticProportion  ...  NR-AhR  NR-Aromatase  NR-ER  NR-ER-LBD  \\\n",
       "mol_id                        ...                                           \n",
       "TOX3021               0.5625  ...       1             0      0          0   \n",
       "TOX3020               0.4000  ...       0             0      0          0   \n",
       "TOX3024               0.0000  ...       0             0      0          0   \n",
       "TOX3027               0.3000  ...       0             0      0          0   \n",
       "TOX20800              0.0000  ...       0             0      0          0   \n",
       "\n",
       "          NR-PPAR-gamma  SR-ARE  SR-ATAD5  SR-HSE  SR-MMP  SR-p53  \n",
       "mol_id                                                             \n",
       "TOX3021               0       1         0       0       0       0  \n",
       "TOX3020               0       0         0       0       0       0  \n",
       "TOX3024               0       0         0       0       0       0  \n",
       "TOX3027               0       0         0       0       0       0  \n",
       "TOX20800              0       0         0       0       0       0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index('mol_id', inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a5e1ced-7103-44cd-9140-cd2f8ae7a07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MolecularWeight', 'LogP', 'TPSA', 'HBDonors', 'HBAcceptors',\n",
       "       'RotatableBonds', 'FractionCSP3', 'HeavyAtoms', 'RingCount',\n",
       "       'AromaticProportion', 'LogS_ESOL', 'PositiveCharges', 'NegativeCharges',\n",
       "       'FormalCharge', 'AromaticRings', 'AromaticHeterocycles',\n",
       "       'AliphaticRings', 'MolecularComplexity', 'MolarRefractivity',\n",
       "       'Heteroatoms', 'HalogenCount', 'PhenolicGroups', 'NR-AR', 'NR-AR-LBD',\n",
       "       'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma',\n",
       "       'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d4d2548-3d00-4285-bd36-fd96867e3c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_0 = df[df['NR-ER'] == 0].sample(n=884, random_state=42)\n",
    "\n",
    "subset_1 = df[df['NR-ER'] == 1]\n",
    "\n",
    "balanced_df = pd.concat([subset_0, subset_1])\n",
    "\n",
    "features_df = balanced_df[['MolecularWeight', 'LogP', 'TPSA', 'HBDonors', 'HBAcceptors',\n",
    "       'RotatableBonds', 'FractionCSP3', 'HeavyAtoms', 'RingCount', 'LogS_ESOL',\n",
    "       'FormalCharge', 'AromaticRings', 'AromaticHeterocycles',\n",
    "       'AliphaticRings', 'MolecularComplexity', 'MolarRefractivity']]\n",
    "\n",
    "target_df = balanced_df[['NR-ER']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a2a2092-954c-4875-8229-1bc1cf50dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_df, target_df, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7017c116",
   "metadata": {},
   "source": [
    "# ANN + SMOTEEN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3989eff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/2000], Loss: 0.6769\n",
      "Epoch [20/2000], Loss: 0.6523\n",
      "Epoch [30/2000], Loss: 0.6409\n",
      "Epoch [40/2000], Loss: 0.6374\n",
      "Epoch [50/2000], Loss: 0.6223\n",
      "Epoch [60/2000], Loss: 0.6192\n",
      "Epoch [70/2000], Loss: 0.6084\n",
      "Epoch [80/2000], Loss: 0.6044\n",
      "Epoch [90/2000], Loss: 0.6055\n",
      "Epoch [100/2000], Loss: 0.6039\n",
      "Epoch [110/2000], Loss: 0.5889\n",
      "Epoch [120/2000], Loss: 0.5839\n",
      "Epoch [130/2000], Loss: 0.5909\n",
      "Epoch [140/2000], Loss: 0.5863\n",
      "Epoch [150/2000], Loss: 0.5737\n",
      "Epoch [160/2000], Loss: 0.5725\n",
      "Epoch [170/2000], Loss: 0.5707\n",
      "Epoch [180/2000], Loss: 0.5568\n",
      "Epoch [190/2000], Loss: 0.5625\n",
      "Epoch [200/2000], Loss: 0.5571\n",
      "Epoch [210/2000], Loss: 0.5476\n",
      "Epoch [220/2000], Loss: 0.5462\n",
      "Epoch [230/2000], Loss: 0.5311\n",
      "Epoch [240/2000], Loss: 0.5385\n",
      "Epoch [250/2000], Loss: 0.5476\n",
      "Epoch [260/2000], Loss: 0.5258\n",
      "Epoch [270/2000], Loss: 0.5359\n",
      "Epoch [280/2000], Loss: 0.5363\n",
      "Epoch [290/2000], Loss: 0.5193\n",
      "Epoch [300/2000], Loss: 0.5317\n",
      "Epoch [310/2000], Loss: 0.5128\n",
      "Epoch [320/2000], Loss: 0.5206\n",
      "Epoch [330/2000], Loss: 0.5250\n",
      "Epoch [340/2000], Loss: 0.5186\n",
      "Epoch [350/2000], Loss: 0.5255\n",
      "Epoch [360/2000], Loss: 0.5118\n",
      "Epoch [370/2000], Loss: 0.5014\n",
      "Epoch [380/2000], Loss: 0.5032\n",
      "Epoch [390/2000], Loss: 0.5034\n",
      "Epoch [400/2000], Loss: 0.4899\n",
      "Epoch [410/2000], Loss: 0.4994\n",
      "Epoch [420/2000], Loss: 0.4963\n",
      "Epoch [430/2000], Loss: 0.4844\n",
      "Epoch [440/2000], Loss: 0.4810\n",
      "Epoch [450/2000], Loss: 0.4793\n",
      "Epoch [460/2000], Loss: 0.4840\n",
      "Epoch [470/2000], Loss: 0.4796\n",
      "Epoch [480/2000], Loss: 0.4806\n",
      "Epoch [490/2000], Loss: 0.4718\n",
      "Epoch [500/2000], Loss: 0.4790\n",
      "Epoch [510/2000], Loss: 0.4747\n",
      "Epoch [520/2000], Loss: 0.4664\n",
      "Epoch [530/2000], Loss: 0.4685\n",
      "Epoch [540/2000], Loss: 0.4558\n",
      "Epoch [550/2000], Loss: 0.4771\n",
      "Epoch [560/2000], Loss: 0.4670\n",
      "Epoch [570/2000], Loss: 0.4556\n",
      "Epoch [580/2000], Loss: 0.4510\n",
      "Epoch [590/2000], Loss: 0.4517\n",
      "Epoch [600/2000], Loss: 0.4518\n",
      "Epoch [610/2000], Loss: 0.4442\n",
      "Epoch [620/2000], Loss: 0.4500\n",
      "Epoch [630/2000], Loss: 0.4421\n",
      "Epoch [640/2000], Loss: 0.4320\n",
      "Epoch [650/2000], Loss: 0.4408\n",
      "Epoch [660/2000], Loss: 0.4258\n",
      "Epoch [670/2000], Loss: 0.4463\n",
      "Epoch [680/2000], Loss: 0.4190\n",
      "Epoch [690/2000], Loss: 0.4035\n",
      "Epoch [700/2000], Loss: 0.4207\n",
      "Epoch [710/2000], Loss: 0.4251\n",
      "Epoch [720/2000], Loss: 0.4095\n",
      "Epoch [730/2000], Loss: 0.4300\n",
      "Epoch [740/2000], Loss: 0.4187\n",
      "Epoch [750/2000], Loss: 0.3986\n",
      "Epoch [760/2000], Loss: 0.4244\n",
      "Epoch [770/2000], Loss: 0.4175\n",
      "Epoch [780/2000], Loss: 0.4078\n",
      "Epoch [790/2000], Loss: 0.4195\n",
      "Epoch [800/2000], Loss: 0.3922\n",
      "Epoch [810/2000], Loss: 0.4156\n",
      "Epoch [820/2000], Loss: 0.3839\n",
      "Epoch [830/2000], Loss: 0.3941\n",
      "Epoch [840/2000], Loss: 0.3991\n",
      "Epoch [850/2000], Loss: 0.3738\n",
      "Epoch [860/2000], Loss: 0.3929\n",
      "Epoch [870/2000], Loss: 0.3851\n",
      "Epoch [880/2000], Loss: 0.3788\n",
      "Epoch [890/2000], Loss: 0.3816\n",
      "Epoch [900/2000], Loss: 0.3857\n",
      "Epoch [910/2000], Loss: 0.3741\n",
      "Epoch [920/2000], Loss: 0.3798\n",
      "Epoch [930/2000], Loss: 0.3858\n",
      "Epoch [940/2000], Loss: 0.3698\n",
      "Epoch [950/2000], Loss: 0.3633\n",
      "Epoch [960/2000], Loss: 0.3662\n",
      "Epoch [970/2000], Loss: 0.3715\n",
      "Epoch [980/2000], Loss: 0.3751\n",
      "Epoch [990/2000], Loss: 0.3548\n",
      "Epoch [1000/2000], Loss: 0.3747\n",
      "Epoch [1010/2000], Loss: 0.3835\n",
      "Epoch [1020/2000], Loss: 0.3533\n",
      "Epoch [1030/2000], Loss: 0.3536\n",
      "Epoch [1040/2000], Loss: 0.3630\n",
      "Epoch [1050/2000], Loss: 0.3650\n",
      "Epoch [1060/2000], Loss: 0.3566\n",
      "Epoch [1070/2000], Loss: 0.3650\n",
      "Epoch [1080/2000], Loss: 0.3439\n",
      "Epoch [1090/2000], Loss: 0.3327\n",
      "Epoch [1100/2000], Loss: 0.3545\n",
      "Epoch [1110/2000], Loss: 0.3531\n",
      "Epoch [1120/2000], Loss: 0.3374\n",
      "Epoch [1130/2000], Loss: 0.3448\n",
      "Epoch [1140/2000], Loss: 0.3546\n",
      "Epoch [1150/2000], Loss: 0.3370\n",
      "Epoch [1160/2000], Loss: 0.3410\n",
      "Epoch [1170/2000], Loss: 0.3427\n",
      "Epoch [1180/2000], Loss: 0.3525\n",
      "Epoch [1190/2000], Loss: 0.3401\n",
      "Epoch [1200/2000], Loss: 0.3475\n",
      "Epoch [1210/2000], Loss: 0.3262\n",
      "Epoch [1220/2000], Loss: 0.3182\n",
      "Epoch [1230/2000], Loss: 0.3490\n",
      "Epoch [1240/2000], Loss: 0.3469\n",
      "Epoch [1250/2000], Loss: 0.3368\n",
      "Epoch [1260/2000], Loss: 0.3137\n",
      "Epoch [1270/2000], Loss: 0.3240\n",
      "Epoch [1280/2000], Loss: 0.3216\n",
      "Epoch [1290/2000], Loss: 0.3402\n",
      "Epoch [1300/2000], Loss: 0.3277\n",
      "Epoch [1310/2000], Loss: 0.3100\n",
      "Epoch [1320/2000], Loss: 0.3092\n",
      "Epoch [1330/2000], Loss: 0.3311\n",
      "Epoch [1340/2000], Loss: 0.3047\n",
      "Epoch [1350/2000], Loss: 0.3186\n",
      "Epoch [1360/2000], Loss: 0.3186\n",
      "Epoch [1370/2000], Loss: 0.3195\n",
      "Epoch [1380/2000], Loss: 0.3054\n",
      "Epoch [1390/2000], Loss: 0.2903\n",
      "Epoch [1400/2000], Loss: 0.3139\n",
      "Epoch [1410/2000], Loss: 0.3247\n",
      "Epoch [1420/2000], Loss: 0.3120\n",
      "Epoch [1430/2000], Loss: 0.2829\n",
      "Epoch [1440/2000], Loss: 0.3257\n",
      "Epoch [1450/2000], Loss: 0.3093\n",
      "Epoch [1460/2000], Loss: 0.3008\n",
      "Epoch [1470/2000], Loss: 0.3137\n",
      "Epoch [1480/2000], Loss: 0.2674\n",
      "Epoch [1490/2000], Loss: 0.3115\n",
      "Epoch [1500/2000], Loss: 0.3030\n",
      "Epoch [1510/2000], Loss: 0.3057\n",
      "Epoch [1520/2000], Loss: 0.2963\n",
      "Epoch [1530/2000], Loss: 0.3052\n",
      "Epoch [1540/2000], Loss: 0.3226\n",
      "Epoch [1550/2000], Loss: 0.3152\n",
      "Epoch [1560/2000], Loss: 0.2909\n",
      "Epoch [1570/2000], Loss: 0.3066\n",
      "Epoch [1580/2000], Loss: 0.3255\n",
      "Epoch [1590/2000], Loss: 0.2856\n",
      "Epoch [1600/2000], Loss: 0.2814\n",
      "Epoch [1610/2000], Loss: 0.2970\n",
      "Epoch [1620/2000], Loss: 0.2689\n",
      "Epoch [1630/2000], Loss: 0.2879\n",
      "Epoch [1640/2000], Loss: 0.2904\n",
      "Epoch [1650/2000], Loss: 0.2869\n",
      "Epoch [1660/2000], Loss: 0.2970\n",
      "Epoch [1670/2000], Loss: 0.2889\n",
      "Epoch [1680/2000], Loss: 0.2737\n",
      "Epoch [1690/2000], Loss: 0.2695\n",
      "Epoch [1700/2000], Loss: 0.2933\n",
      "Epoch [1710/2000], Loss: 0.2879\n",
      "Epoch [1720/2000], Loss: 0.2818\n",
      "Epoch [1730/2000], Loss: 0.2835\n",
      "Epoch [1740/2000], Loss: 0.3004\n",
      "Epoch [1750/2000], Loss: 0.2911\n",
      "Epoch [1760/2000], Loss: 0.2683\n",
      "Epoch [1770/2000], Loss: 0.2875\n",
      "Epoch [1780/2000], Loss: 0.2693\n",
      "Epoch [1790/2000], Loss: 0.2932\n",
      "Epoch [1800/2000], Loss: 0.2570\n",
      "Epoch [1810/2000], Loss: 0.2853\n",
      "Epoch [1820/2000], Loss: 0.2576\n",
      "Epoch [1830/2000], Loss: 0.2862\n",
      "Epoch [1840/2000], Loss: 0.2717\n",
      "Epoch [1850/2000], Loss: 0.3002\n",
      "Epoch [1860/2000], Loss: 0.2627\n",
      "Epoch [1870/2000], Loss: 0.2756\n",
      "Epoch [1880/2000], Loss: 0.2644\n",
      "Epoch [1890/2000], Loss: 0.2883\n",
      "Epoch [1900/2000], Loss: 0.2729\n",
      "Epoch [1910/2000], Loss: 0.2812\n",
      "Epoch [1920/2000], Loss: 0.2777\n",
      "Epoch [1930/2000], Loss: 0.2563\n",
      "Epoch [1940/2000], Loss: 0.2605\n",
      "Epoch [1950/2000], Loss: 0.2678\n",
      "Epoch [1960/2000], Loss: 0.2713\n",
      "Epoch [1970/2000], Loss: 0.2705\n",
      "Epoch [1980/2000], Loss: 0.2713\n",
      "Epoch [1990/2000], Loss: 0.2632\n",
      "Epoch [2000/2000], Loss: 0.2510\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.62      0.64       177\n",
      "         1.0       0.65      0.70      0.67       177\n",
      "\n",
      "    accuracy                           0.66       354\n",
      "   macro avg       0.66      0.66      0.66       354\n",
      "weighted avg       0.66      0.66      0.66       354\n",
      "\n",
      "AUC-ROC: 0.72421717897156\n",
      "Epoch [10/100], Loss: 0.7000\n",
      "Epoch [20/100], Loss: 0.6853\n",
      "Epoch [30/100], Loss: 0.6741\n",
      "Epoch [40/100], Loss: 0.6670\n",
      "Epoch [50/100], Loss: 0.6563\n",
      "Epoch [60/100], Loss: 0.6520\n",
      "Epoch [70/100], Loss: 0.6476\n",
      "Epoch [80/100], Loss: 0.6410\n",
      "Epoch [90/100], Loss: 0.6383\n",
      "Epoch [100/100], Loss: 0.6321\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.76      0.70       177\n",
      "         1.0       0.71      0.59      0.65       177\n",
      "\n",
      "    accuracy                           0.68       354\n",
      "   macro avg       0.68      0.68      0.67       354\n",
      "weighted avg       0.68      0.68      0.67       354\n",
      "\n",
      "AUC-ROC: 0.7360911615436176\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Convert data to numpy and split ---\n",
    "X = features_df.values.astype(np.float32)\n",
    "y = target_df.values.astype(np.float32).ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# --- 2. Standardize features ---\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# --- 3. Convert to torch tensors ---\n",
    "X_train_tensor = torch.tensor(X_train)\n",
    "y_train_tensor = torch.tensor(y_train).unsqueeze(1)  # shape: (batch, 1)\n",
    "X_test_tensor = torch.tensor(X_test)\n",
    "y_test_tensor = torch.tensor(y_test).unsqueeze(1)\n",
    "\n",
    "# --- 4. Define the ANN model ---\n",
    "class ANNModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ANNModel, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "        nn.Linear(input_dim, 128),\n",
    "        nn.BatchNorm1d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "\n",
    "        nn.Linear(128, 64),\n",
    "        nn.BatchNorm1d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "\n",
    "        nn.Linear(64, 32),\n",
    "        nn.BatchNorm1d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "\n",
    "        nn.Linear(32, 1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "model = ANNModel(X_train.shape[1])\n",
    "\n",
    "# --- 5. Loss and Optimizer ---\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# --- 6. Training loop ---\n",
    "epochs = 2000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# --- 7. Evaluation ---\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_proba = model(X_test_tensor).numpy()\n",
    "    y_pred_label = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_label))\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, y_pred_proba))\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class ToxMLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ToxMLP, self).__init__()\n",
    "        self.network = nn.Sequential(            \n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "model = ToxMLP(X_train.shape[1])\n",
    "\n",
    "# --- 5. Loss and Optimizer ---\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# --- 6. Training loop ---\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# --- 7. Evaluation ---\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_proba = model(X_test_tensor).numpy()\n",
    "    y_pred_label = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_label))\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a856e5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch model weights saved to: tox_mlp_model_weights.pth\n",
      "StandardScaler saved to: standard_scaler.joblib\n",
      "\n",
      "Model and scaler saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Define the file paths for your saved model and scaler\n",
    "MODEL_PATH = 'tox_mlp_model_weights.pth'\n",
    "SCALER_PATH = 'standard_scaler.joblib'\n",
    "\n",
    "# 1. Save the model's state_dict (weights and biases)\n",
    "# This is the recommended way to save PyTorch models.\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "print(f\"PyTorch model weights saved to: {MODEL_PATH}\")\n",
    "\n",
    "# 2. Save the StandardScaler object\n",
    "# This is crucial because new data must be scaled using the *same* scaler\n",
    "# that was fitted on the training data.\n",
    "joblib.dump(scaler, SCALER_PATH)\n",
    "print(f\"StandardScaler saved to: {SCALER_PATH}\")\n",
    "\n",
    "print(\"\\nModel and scaler saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e4d635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
