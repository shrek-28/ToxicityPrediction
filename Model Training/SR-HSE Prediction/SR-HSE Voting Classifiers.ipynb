{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b811d579",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18e471ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b32590d",
   "metadata": {},
   "source": [
    "# Data Read In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ace17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mol_id</th>\n",
       "      <th>MolecularWeight</th>\n",
       "      <th>LogP</th>\n",
       "      <th>TPSA</th>\n",
       "      <th>HBDonors</th>\n",
       "      <th>HBAcceptors</th>\n",
       "      <th>RotatableBonds</th>\n",
       "      <th>FractionCSP3</th>\n",
       "      <th>HeavyAtoms</th>\n",
       "      <th>RingCount</th>\n",
       "      <th>...</th>\n",
       "      <th>NR-AhR</th>\n",
       "      <th>NR-Aromatase</th>\n",
       "      <th>NR-ER</th>\n",
       "      <th>NR-ER-LBD</th>\n",
       "      <th>NR-PPAR-gamma</th>\n",
       "      <th>SR-ARE</th>\n",
       "      <th>SR-ATAD5</th>\n",
       "      <th>SR-HSE</th>\n",
       "      <th>SR-MMP</th>\n",
       "      <th>SR-p53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOX3021</td>\n",
       "      <td>258.324</td>\n",
       "      <td>1.34240</td>\n",
       "      <td>82.28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOX3020</td>\n",
       "      <td>204.229</td>\n",
       "      <td>1.29940</td>\n",
       "      <td>49.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOX3024</td>\n",
       "      <td>288.475</td>\n",
       "      <td>5.09030</td>\n",
       "      <td>20.23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TOX3027</td>\n",
       "      <td>276.424</td>\n",
       "      <td>3.75244</td>\n",
       "      <td>32.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOX20800</td>\n",
       "      <td>206.027</td>\n",
       "      <td>-0.99220</td>\n",
       "      <td>135.29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mol_id  MolecularWeight     LogP    TPSA  HBDonors  HBAcceptors  \\\n",
       "0   TOX3021          258.324  1.34240   82.28       1.0          5.0   \n",
       "1   TOX3020          204.229  1.29940   49.41       1.0          2.0   \n",
       "2   TOX3024          288.475  5.09030   20.23       1.0          1.0   \n",
       "3   TOX3027          276.424  3.75244   32.34       1.0          2.0   \n",
       "4  TOX20800          206.027 -0.99220  135.29       5.0          3.0   \n",
       "\n",
       "   RotatableBonds  FractionCSP3  HeavyAtoms  RingCount  ...  NR-AhR  \\\n",
       "0             3.0      0.222222        16.0        2.0  ...       1   \n",
       "1             2.0      0.272727        15.0        2.0  ...       0   \n",
       "2             1.0      0.900000        21.0        4.0  ...       0   \n",
       "3             7.0      0.588235        20.0        1.0  ...       0   \n",
       "4             2.0      1.000000        11.0        0.0  ...       0   \n",
       "\n",
       "   NR-Aromatase  NR-ER  NR-ER-LBD  NR-PPAR-gamma  SR-ARE  SR-ATAD5  SR-HSE  \\\n",
       "0             0      0          0              0       1         0       0   \n",
       "1             0      0          0              0       0         0       0   \n",
       "2             0      0          0              0       0         0       0   \n",
       "3             0      0          0              0       0         0       0   \n",
       "4             0      0          0              0       0         0       0   \n",
       "\n",
       "   SR-MMP  SR-p53  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "2       0       0  \n",
       "3       0       0  \n",
       "4       0       0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../DATA/filled_toxicity_df.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61296d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MolecularWeight</th>\n",
       "      <th>LogP</th>\n",
       "      <th>TPSA</th>\n",
       "      <th>HBDonors</th>\n",
       "      <th>HBAcceptors</th>\n",
       "      <th>RotatableBonds</th>\n",
       "      <th>FractionCSP3</th>\n",
       "      <th>HeavyAtoms</th>\n",
       "      <th>RingCount</th>\n",
       "      <th>AromaticProportion</th>\n",
       "      <th>...</th>\n",
       "      <th>NR-AhR</th>\n",
       "      <th>NR-Aromatase</th>\n",
       "      <th>NR-ER</th>\n",
       "      <th>NR-ER-LBD</th>\n",
       "      <th>NR-PPAR-gamma</th>\n",
       "      <th>SR-ARE</th>\n",
       "      <th>SR-ATAD5</th>\n",
       "      <th>SR-HSE</th>\n",
       "      <th>SR-MMP</th>\n",
       "      <th>SR-p53</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mol_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TOX3021</th>\n",
       "      <td>258.324</td>\n",
       "      <td>1.34240</td>\n",
       "      <td>82.28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOX3020</th>\n",
       "      <td>204.229</td>\n",
       "      <td>1.29940</td>\n",
       "      <td>49.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOX3024</th>\n",
       "      <td>288.475</td>\n",
       "      <td>5.09030</td>\n",
       "      <td>20.23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOX3027</th>\n",
       "      <td>276.424</td>\n",
       "      <td>3.75244</td>\n",
       "      <td>32.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOX20800</th>\n",
       "      <td>206.027</td>\n",
       "      <td>-0.99220</td>\n",
       "      <td>135.29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          MolecularWeight     LogP    TPSA  HBDonors  HBAcceptors  \\\n",
       "mol_id                                                              \n",
       "TOX3021           258.324  1.34240   82.28       1.0          5.0   \n",
       "TOX3020           204.229  1.29940   49.41       1.0          2.0   \n",
       "TOX3024           288.475  5.09030   20.23       1.0          1.0   \n",
       "TOX3027           276.424  3.75244   32.34       1.0          2.0   \n",
       "TOX20800          206.027 -0.99220  135.29       5.0          3.0   \n",
       "\n",
       "          RotatableBonds  FractionCSP3  HeavyAtoms  RingCount  \\\n",
       "mol_id                                                          \n",
       "TOX3021              3.0      0.222222        16.0        2.0   \n",
       "TOX3020              2.0      0.272727        15.0        2.0   \n",
       "TOX3024              1.0      0.900000        21.0        4.0   \n",
       "TOX3027              7.0      0.588235        20.0        1.0   \n",
       "TOX20800             2.0      1.000000        11.0        0.0   \n",
       "\n",
       "          AromaticProportion  ...  NR-AhR  NR-Aromatase  NR-ER  NR-ER-LBD  \\\n",
       "mol_id                        ...                                           \n",
       "TOX3021               0.5625  ...       1             0      0          0   \n",
       "TOX3020               0.4000  ...       0             0      0          0   \n",
       "TOX3024               0.0000  ...       0             0      0          0   \n",
       "TOX3027               0.3000  ...       0             0      0          0   \n",
       "TOX20800              0.0000  ...       0             0      0          0   \n",
       "\n",
       "          NR-PPAR-gamma  SR-ARE  SR-ATAD5  SR-HSE  SR-MMP  SR-p53  \n",
       "mol_id                                                             \n",
       "TOX3021               0       1         0       0       0       0  \n",
       "TOX3020               0       0         0       0       0       0  \n",
       "TOX3024               0       0         0       0       0       0  \n",
       "TOX3027               0       0         0       0       0       0  \n",
       "TOX20800              0       0         0       0       0       0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index('mol_id', inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c2e2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MolecularWeight', 'LogP', 'TPSA', 'HBDonors', 'HBAcceptors',\n",
       "       'RotatableBonds', 'FractionCSP3', 'HeavyAtoms', 'RingCount',\n",
       "       'AromaticProportion', 'LogS_ESOL', 'PositiveCharges', 'NegativeCharges',\n",
       "       'FormalCharge', 'AromaticRings', 'AromaticHeterocycles',\n",
       "       'AliphaticRings', 'MolecularComplexity', 'MolarRefractivity',\n",
       "       'Heteroatoms', 'HalogenCount', 'PhenolicGroups', 'NR-AR', 'NR-AR-LBD',\n",
       "       'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma',\n",
       "       'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85bc2b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_0 = df[df['SR-HSE'] == 0].sample(n=884, random_state=42)\n",
    "\n",
    "subset_1 = df[df['SR-HSE'] == 1]\n",
    "\n",
    "balanced_df = pd.concat([subset_0, subset_1])\n",
    "\n",
    "features_df = balanced_df[['MolecularWeight', 'LogP', 'TPSA', 'HBDonors', 'HBAcceptors',\n",
    "       'RotatableBonds', 'FractionCSP3', 'HeavyAtoms', 'RingCount', 'LogS_ESOL',\n",
    "       'FormalCharge', 'AromaticRings', 'AromaticHeterocycles',\n",
    "       'AliphaticRings', 'MolecularComplexity', 'MolarRefractivity']]\n",
    "\n",
    "target_df = balanced_df[['SR-HSE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2887e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_df, target_df, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d705ee9",
   "metadata": {},
   "source": [
    "# Voting Classifier\n",
    "\n",
    "### with ```LogisticRegression```, ```RandomForestClassifier``` and ```XGBoost```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "419dd848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR AUC: 0.7062\n",
      "RF AUC: 0.6930\n",
      "XGB AUC: 0.6961\n",
      "Ensemble AUC: 0.7127\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    features_df, target_df.values.ravel(),\n",
    "    test_size=0.2, stratify=target_df, random_state=42\n",
    ")\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000, random_state=42)\n",
    "logreg_params = {\n",
    "    'C': [0.1, 1, 10]\n",
    "}\n",
    "logreg_grid = GridSearchCV(logreg, logreg_params, cv=5, scoring='roc_auc', n_jobs=1)\n",
    "logreg_grid.fit(X_train, y_train)\n",
    "best_logreg = logreg_grid.best_estimator_\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10]\n",
    "}\n",
    "rf_grid = GridSearchCV(rf, rf_params, cv=5, scoring='roc_auc', n_jobs=1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "xgb = XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1]\n",
    "}\n",
    "xgb_grid = GridSearchCV(xgb, xgb_params, cv=5, scoring='roc_auc', n_jobs=1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', best_logreg),\n",
    "        ('rf', best_rf),\n",
    "        ('xgb', best_xgb)\n",
    "    ],\n",
    "    voting='soft' \n",
    ")\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "for name, model in voting_clf.named_estimators_.items():\n",
    "    y_proba = model.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, y_proba)\n",
    "    print(f\"{name.upper()} AUC: {auc:.4f}\")\n",
    "\n",
    "y_pred_proba = voting_clf.predict_proba(X_val)[:, 1]\n",
    "ensemble_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f\"Ensemble AUC: {ensemble_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57dad055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Classification Reports ---\n",
      "\n",
      "LR Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.88      0.78       177\n",
      "           1       0.52      0.27      0.36        88\n",
      "\n",
      "    accuracy                           0.68       265\n",
      "   macro avg       0.61      0.57      0.57       265\n",
      "weighted avg       0.65      0.68      0.64       265\n",
      "\n",
      "------------------------------------------------------------\n",
      "RF Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.77       177\n",
      "           1       0.52      0.35      0.42        88\n",
      "\n",
      "    accuracy                           0.68       265\n",
      "   macro avg       0.62      0.59      0.60       265\n",
      "weighted avg       0.65      0.68      0.66       265\n",
      "\n",
      "------------------------------------------------------------\n",
      "XGB Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.83      0.78       177\n",
      "           1       0.52      0.38      0.44        88\n",
      "\n",
      "    accuracy                           0.68       265\n",
      "   macro avg       0.63      0.60      0.61       265\n",
      "weighted avg       0.66      0.68      0.66       265\n",
      "\n",
      "------------------------------------------------------------\n",
      "ENSEMBLE Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79       177\n",
      "           1       0.56      0.34      0.42        88\n",
      "\n",
      "    accuracy                           0.69       265\n",
      "   macro avg       0.64      0.60      0.61       265\n",
      "weighted avg       0.67      0.69      0.67       265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"\\n--- Classification Reports ---\\n\")\n",
    "\n",
    "for name, model in voting_clf.named_estimators_.items():\n",
    "    y_pred = model.predict(X_val)\n",
    "    print(f\"{name.upper()} Classification Report:\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print('-' * 60)\n",
    "\n",
    "# Ensemble model\n",
    "ensemble_pred = voting_clf.predict(X_val)\n",
    "print(\"ENSEMBLE Classification Report:\")\n",
    "print(classification_report(y_val, ensemble_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3b929a",
   "metadata": {},
   "source": [
    "# 2: Only XGBoost and RF with Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a36cf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RF AUC: 0.6676\n",
      "RF Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.62      0.68       177\n",
      "           1       0.44      0.59      0.50        88\n",
      "\n",
      "    accuracy                           0.61       265\n",
      "   macro avg       0.60      0.61      0.59       265\n",
      "weighted avg       0.65      0.61      0.62       265\n",
      "\n",
      "\n",
      "XGB AUC: 0.6620\n",
      "XGB Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.64      0.70       177\n",
      "           1       0.45      0.58      0.50        88\n",
      "\n",
      "    accuracy                           0.62       265\n",
      "   macro avg       0.60      0.61      0.60       265\n",
      "weighted avg       0.65      0.62      0.63       265\n",
      "\n",
      "\n",
      "Ensemble AUC: 0.6628\n",
      "Ensemble Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.62      0.68       177\n",
      "           1       0.44      0.59      0.50        88\n",
      "\n",
      "    accuracy                           0.61       265\n",
      "   macro avg       0.60      0.61      0.59       265\n",
      "weighted avg       0.65      0.61      0.62       265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# 1. Train-test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    features_df, target_df.values.ravel(),\n",
    "    test_size=0.2, stratify=target_df, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Apply SMOTEEN on training data only\n",
    "smoteen = SMOTEENN(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smoteen.fit_resample(X_train, y_train)\n",
    "\n",
    "# 4. Random Forest + GridSearchCV\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_params = {'n_estimators': [100, 200], 'max_depth': [None, 10]}\n",
    "rf_grid = GridSearchCV(rf, rf_params, cv=5, scoring='roc_auc', n_jobs=1)\n",
    "rf_grid.fit(X_train_resampled, y_train_resampled)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "\n",
    "# 5. XGBoost + GridSearchCV\n",
    "xgb = XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "xgb_params = {'n_estimators': [100, 200], 'learning_rate': [0.05, 0.1]}\n",
    "xgb_grid = GridSearchCV(xgb, xgb_params, cv=5, scoring='roc_auc', n_jobs=1)\n",
    "xgb_grid.fit(X_train_resampled, y_train_resampled)\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "\n",
    "# 6. Voting Classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', best_rf),\n",
    "        ('xgb', best_xgb)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "voting_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 7. AUC + Classification Report for individual models\n",
    "for name, model in voting_clf.named_estimators_.items():\n",
    "    y_proba = model.predict_proba(X_val)[:, 1]\n",
    "    y_pred = model.predict(X_val)\n",
    "    auc = roc_auc_score(y_val, y_proba)\n",
    "    print(f\"\\n{name.upper()} AUC: {auc:.4f}\")\n",
    "    print(f\"{name.upper()} Classification Report:\\n{classification_report(y_val, y_pred)}\")\n",
    "\n",
    "# 8. Ensemble AUC + Classification Report\n",
    "y_pred_proba = voting_clf.predict_proba(X_val)[:, 1]\n",
    "y_pred_ensemble = voting_clf.predict(X_val)\n",
    "ensemble_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f\"\\nEnsemble AUC: {ensemble_auc:.4f}\")\n",
    "print(f\"Ensemble Classification Report:\\n{classification_report(y_val, y_pred_ensemble)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04992bad",
   "metadata": {},
   "source": [
    "# 3: Additional Models: GB, ET, KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7fd2daf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB Training started\n",
      "GB Training ended\n",
      "ET Training started\n",
      "ET Training ended\n",
      "KNN Training started\n",
      "KNN Training ended\n",
      "\n",
      "GB AUC: 0.6657\n",
      "GB Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.63      0.68       177\n",
      "           1       0.42      0.53      0.47        88\n",
      "\n",
      "    accuracy                           0.60       265\n",
      "   macro avg       0.58      0.58      0.57       265\n",
      "weighted avg       0.63      0.60      0.61       265\n",
      "\n",
      "\n",
      "ET AUC: 0.6713\n",
      "ET Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.69      0.72       177\n",
      "           1       0.48      0.57      0.52        88\n",
      "\n",
      "    accuracy                           0.65       265\n",
      "   macro avg       0.62      0.63      0.62       265\n",
      "weighted avg       0.67      0.65      0.66       265\n",
      "\n",
      "\n",
      "KNN AUC: 0.5256\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.53      0.59       177\n",
      "           1       0.35      0.51      0.41        88\n",
      "\n",
      "    accuracy                           0.52       265\n",
      "   macro avg       0.52      0.52      0.50       265\n",
      "weighted avg       0.57      0.52      0.53       265\n",
      "\n",
      "\n",
      "RF AUC: 0.6676\n",
      "RF Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.62      0.68       177\n",
      "           1       0.44      0.59      0.50        88\n",
      "\n",
      "    accuracy                           0.61       265\n",
      "   macro avg       0.60      0.61      0.59       265\n",
      "weighted avg       0.65      0.61      0.62       265\n",
      "\n",
      "\n",
      "XGB AUC: 0.6620\n",
      "XGB Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.64      0.70       177\n",
      "           1       0.45      0.58      0.50        88\n",
      "\n",
      "    accuracy                           0.62       265\n",
      "   macro avg       0.60      0.61      0.60       265\n",
      "weighted avg       0.65      0.62      0.63       265\n",
      "\n",
      "\n",
      "Ensemble AUC: 0.6443\n",
      "Ensemble Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.63      0.69       177\n",
      "           1       0.44      0.59      0.50        88\n",
      "\n",
      "    accuracy                           0.62       265\n",
      "   macro avg       0.60      0.61      0.60       265\n",
      "weighted avg       0.65      0.62      0.63       265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "import joblib\n",
    "\n",
    "# --- Define models and hyperparameters ---\n",
    "model_configs = {\n",
    "    'gb': {\n",
    "        'model': GradientBoostingClassifier(random_state=42),\n",
    "        'params': {'n_estimators': [100], 'learning_rate': [0.1]}\n",
    "    },\n",
    "    'et': {\n",
    "        'model': ExtraTreesClassifier(random_state=42),\n",
    "        'params': {'n_estimators': [100], 'max_depth': [None]}\n",
    "    },\n",
    "    'knn': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {'n_neighbors': [3, 5]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- Train models in loop using parallel grid search ---\n",
    "best_models = {}\n",
    "\n",
    "for name, config in model_configs.items():\n",
    "    print(f\"{name.upper()} Training started\")\n",
    "    grid = GridSearchCV(\n",
    "        estimator=config['model'],\n",
    "        param_grid=config['params'],\n",
    "        cv=5,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=1  # Full parallel grid search\n",
    "    )\n",
    "    grid.fit(X_train_resampled, y_train_resampled)\n",
    "    best_models[name] = grid.best_estimator_\n",
    "    print(f\"{name.upper()} Training ended\")\n",
    "\n",
    "# --- Add existing models ---\n",
    "best_models['rf'] = best_rf\n",
    "best_models['xgb'] = best_xgb\n",
    "\n",
    "# --- Soft Voting Ensemble ---\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[(name, model) for name, model in best_models.items()],\n",
    "    voting='soft',\n",
    "    n_jobs=1  # Parallel prediction across models\n",
    ")\n",
    "voting_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# --- Evaluation loop ---\n",
    "for name, model in voting_clf.named_estimators_.items():\n",
    "    try:\n",
    "        y_proba = model.predict_proba(X_val)[:, 1]\n",
    "    except AttributeError:\n",
    "        print(f\"{name.upper()} does not support predict_proba. Skipping AUC.\")\n",
    "        y_proba = None\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "    if y_proba is not None:\n",
    "        auc = roc_auc_score(y_val, y_proba)\n",
    "        print(f\"\\n{name.upper()} AUC: {auc:.4f}\")\n",
    "    print(f\"{name.upper()} Classification Report:\\n{classification_report(y_val, y_pred)}\")\n",
    "\n",
    "# --- Ensemble Evaluation ---\n",
    "y_pred_proba = voting_clf.predict_proba(X_val)[:, 1]\n",
    "y_pred_ensemble = voting_clf.predict(X_val)\n",
    "ensemble_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f\"\\nEnsemble AUC: {ensemble_auc:.4f}\")\n",
    "print(f\"Ensemble Classification Report:\\n{classification_report(y_val, y_pred_ensemble)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642152ef",
   "metadata": {},
   "source": [
    "# 4: Added ANN to the Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89f0200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0adad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(features_df, target_df, test_size=0.3, stratify=target_df, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fc1f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_train_res, y_train_res = smote_enn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a2e0e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77e7e030",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "y_train_tensor = torch.FloatTensor(y_train_res.values.ravel())\n",
    "\n",
    "X_val_tensor = torch.FloatTensor(X_val_scaled)\n",
    "y_val_tensor = torch.FloatTensor(y_val.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b33dfd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_et = best_models['et']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2fbe669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6680\u001b[0m  0.0129\n",
      "      2        \u001b[36m0.6508\u001b[0m  0.0127\n",
      "      3        \u001b[36m0.6345\u001b[0m  0.0121\n",
      "      4        \u001b[36m0.6191\u001b[0m  0.0128\n",
      "      5        \u001b[36m0.6035\u001b[0m  0.0121\n",
      "      6        \u001b[36m0.5881\u001b[0m  0.0139\n",
      "      7        \u001b[36m0.5739\u001b[0m  0.0181\n",
      "      8        \u001b[36m0.5605\u001b[0m  0.0241\n",
      "      9        \u001b[36m0.5488\u001b[0m  0.0135\n",
      "     10        \u001b[36m0.5372\u001b[0m  0.0232\n",
      "     11        \u001b[36m0.5289\u001b[0m  0.0175\n",
      "     12        \u001b[36m0.5206\u001b[0m  0.0129\n",
      "     13        \u001b[36m0.5136\u001b[0m  0.0157\n",
      "     14        \u001b[36m0.5067\u001b[0m  0.0134\n",
      "     15        \u001b[36m0.5002\u001b[0m  0.0150\n",
      "     16        \u001b[36m0.4941\u001b[0m  0.0128\n",
      "     17        \u001b[36m0.4876\u001b[0m  0.0138\n",
      "     18        \u001b[36m0.4816\u001b[0m  0.0113\n",
      "     19        \u001b[36m0.4751\u001b[0m  0.0126\n",
      "     20        \u001b[36m0.4685\u001b[0m  0.0154\n",
      "     21        \u001b[36m0.4623\u001b[0m  0.0130\n",
      "     22        \u001b[36m0.4561\u001b[0m  0.0200\n",
      "     23        \u001b[36m0.4490\u001b[0m  0.0151\n",
      "     24        \u001b[36m0.4425\u001b[0m  0.0143\n",
      "     25        \u001b[36m0.4360\u001b[0m  0.0146\n",
      "     26        \u001b[36m0.4290\u001b[0m  0.0208\n",
      "     27        \u001b[36m0.4218\u001b[0m  0.0247\n",
      "     28        \u001b[36m0.4149\u001b[0m  0.0144\n",
      "     29        \u001b[36m0.4083\u001b[0m  0.0156\n",
      "     30        \u001b[36m0.4019\u001b[0m  0.0146\n",
      "     31        \u001b[36m0.3950\u001b[0m  0.0143\n",
      "     32        \u001b[36m0.3885\u001b[0m  0.0158\n",
      "     33        \u001b[36m0.3820\u001b[0m  0.0178\n",
      "     34        \u001b[36m0.3763\u001b[0m  0.0180\n",
      "     35        \u001b[36m0.3698\u001b[0m  0.0150\n",
      "     36        \u001b[36m0.3644\u001b[0m  0.0148\n",
      "     37        \u001b[36m0.3582\u001b[0m  0.0153\n",
      "     38        \u001b[36m0.3527\u001b[0m  0.0125\n",
      "     39        \u001b[36m0.3473\u001b[0m  0.0106\n",
      "     40        \u001b[36m0.3417\u001b[0m  0.0113\n",
      "     41        \u001b[36m0.3372\u001b[0m  0.0135\n",
      "     42        \u001b[36m0.3316\u001b[0m  0.0141\n",
      "     43        \u001b[36m0.3273\u001b[0m  0.0139\n",
      "     44        \u001b[36m0.3224\u001b[0m  0.0187\n",
      "     45        \u001b[36m0.3183\u001b[0m  0.0125\n",
      "     46        \u001b[36m0.3135\u001b[0m  0.0162\n",
      "     47        \u001b[36m0.3089\u001b[0m  0.0203\n",
      "     48        \u001b[36m0.3048\u001b[0m  0.0122\n",
      "     49        \u001b[36m0.3007\u001b[0m  0.0165\n",
      "     50        \u001b[36m0.2974\u001b[0m  0.0127\n",
      "     51        \u001b[36m0.2935\u001b[0m  0.0158\n",
      "     52        \u001b[36m0.2891\u001b[0m  0.0150\n",
      "     53        \u001b[36m0.2855\u001b[0m  0.0125\n",
      "     54        \u001b[36m0.2830\u001b[0m  0.0125\n",
      "     55        \u001b[36m0.2791\u001b[0m  0.0120\n",
      "     56        \u001b[36m0.2757\u001b[0m  0.0290\n",
      "     57        \u001b[36m0.2734\u001b[0m  0.0207\n",
      "     58        \u001b[36m0.2691\u001b[0m  0.0215\n",
      "     59        \u001b[36m0.2650\u001b[0m  0.0219\n",
      "     60        \u001b[36m0.2620\u001b[0m  0.0187\n",
      "     61        \u001b[36m0.2592\u001b[0m  0.0169\n",
      "     62        \u001b[36m0.2559\u001b[0m  0.0155\n",
      "     63        \u001b[36m0.2535\u001b[0m  0.0201\n",
      "     64        \u001b[36m0.2497\u001b[0m  0.0142\n",
      "     65        \u001b[36m0.2467\u001b[0m  0.0138\n",
      "     66        \u001b[36m0.2441\u001b[0m  0.0146\n",
      "     67        \u001b[36m0.2413\u001b[0m  0.0187\n",
      "     68        \u001b[36m0.2383\u001b[0m  0.0162\n",
      "     69        \u001b[36m0.2354\u001b[0m  0.0187\n",
      "     70        \u001b[36m0.2332\u001b[0m  0.0170\n",
      "     71        \u001b[36m0.2300\u001b[0m  0.0212\n",
      "     72        \u001b[36m0.2288\u001b[0m  0.0174\n",
      "     73        \u001b[36m0.2244\u001b[0m  0.0172\n",
      "     74        \u001b[36m0.2219\u001b[0m  0.0130\n",
      "     75        \u001b[36m0.2192\u001b[0m  0.0146\n",
      "     76        \u001b[36m0.2171\u001b[0m  0.0135\n",
      "     77        \u001b[36m0.2147\u001b[0m  0.0138\n",
      "     78        \u001b[36m0.2117\u001b[0m  0.0142\n",
      "     79        \u001b[36m0.2097\u001b[0m  0.0138\n",
      "     80        \u001b[36m0.2069\u001b[0m  0.0182\n",
      "     81        \u001b[36m0.2048\u001b[0m  0.0182\n",
      "     82        \u001b[36m0.2020\u001b[0m  0.0167\n",
      "     83        \u001b[36m0.1995\u001b[0m  0.0126\n",
      "     84        \u001b[36m0.1970\u001b[0m  0.0146\n",
      "     85        \u001b[36m0.1946\u001b[0m  0.0163\n",
      "     86        \u001b[36m0.1923\u001b[0m  0.0126\n",
      "     87        \u001b[36m0.1899\u001b[0m  0.0208\n",
      "     88        \u001b[36m0.1878\u001b[0m  0.0159\n",
      "     89        \u001b[36m0.1857\u001b[0m  0.0165\n",
      "     90        \u001b[36m0.1834\u001b[0m  0.0139\n",
      "     91        \u001b[36m0.1819\u001b[0m  0.0147\n",
      "     92        \u001b[36m0.1795\u001b[0m  0.0174\n",
      "     93        \u001b[36m0.1770\u001b[0m  0.0164\n",
      "     94        \u001b[36m0.1745\u001b[0m  0.0155\n",
      "     95        \u001b[36m0.1723\u001b[0m  0.0152\n",
      "     96        \u001b[36m0.1707\u001b[0m  0.0162\n",
      "     97        \u001b[36m0.1688\u001b[0m  0.0161\n",
      "     98        \u001b[36m0.1667\u001b[0m  0.0184\n",
      "     99        \u001b[36m0.1648\u001b[0m  0.0137\n",
      "    100        \u001b[36m0.1628\u001b[0m  0.0183\n",
      "    101        \u001b[36m0.1604\u001b[0m  0.0192\n",
      "    102        \u001b[36m0.1581\u001b[0m  0.0201\n",
      "    103        \u001b[36m0.1552\u001b[0m  0.0120\n",
      "    104        \u001b[36m0.1543\u001b[0m  0.0154\n",
      "    105        \u001b[36m0.1537\u001b[0m  0.0145\n",
      "    106        \u001b[36m0.1503\u001b[0m  0.0160\n",
      "    107        \u001b[36m0.1495\u001b[0m  0.0152\n",
      "    108        \u001b[36m0.1475\u001b[0m  0.0138\n",
      "    109        \u001b[36m0.1453\u001b[0m  0.0170\n",
      "    110        \u001b[36m0.1424\u001b[0m  0.0132\n",
      "    111        \u001b[36m0.1407\u001b[0m  0.0130\n",
      "    112        \u001b[36m0.1391\u001b[0m  0.0135\n",
      "    113        \u001b[36m0.1371\u001b[0m  0.0129\n",
      "    114        \u001b[36m0.1355\u001b[0m  0.0136\n",
      "    115        \u001b[36m0.1335\u001b[0m  0.0116\n",
      "    116        \u001b[36m0.1324\u001b[0m  0.0167\n",
      "    117        \u001b[36m0.1311\u001b[0m  0.0146\n",
      "    118        \u001b[36m0.1285\u001b[0m  0.0121\n",
      "    119        \u001b[36m0.1274\u001b[0m  0.0213\n",
      "    120        \u001b[36m0.1247\u001b[0m  0.0156\n",
      "    121        0.1264  0.0112\n",
      "    122        \u001b[36m0.1232\u001b[0m  0.0125\n",
      "    123        \u001b[36m0.1213\u001b[0m  0.0169\n",
      "    124        \u001b[36m0.1198\u001b[0m  0.0217\n",
      "    125        \u001b[36m0.1180\u001b[0m  0.0214\n",
      "    126        \u001b[36m0.1166\u001b[0m  0.0168\n",
      "    127        \u001b[36m0.1149\u001b[0m  0.0545\n",
      "    128        \u001b[36m0.1128\u001b[0m  0.3028\n",
      "    129        \u001b[36m0.1124\u001b[0m  0.0141\n",
      "    130        \u001b[36m0.1110\u001b[0m  0.0477\n",
      "    131        \u001b[36m0.1095\u001b[0m  0.0277\n",
      "    132        \u001b[36m0.1079\u001b[0m  0.0154\n",
      "    133        \u001b[36m0.1061\u001b[0m  0.0161\n",
      "    134        \u001b[36m0.1058\u001b[0m  0.0134\n",
      "    135        \u001b[36m0.1056\u001b[0m  0.0162\n",
      "    136        \u001b[36m0.1025\u001b[0m  0.0129\n",
      "    137        \u001b[36m0.1021\u001b[0m  0.0137\n",
      "    138        \u001b[36m0.1002\u001b[0m  0.0173\n",
      "    139        \u001b[36m0.0992\u001b[0m  0.0119\n",
      "    140        \u001b[36m0.0978\u001b[0m  0.0130\n",
      "    141        \u001b[36m0.0966\u001b[0m  0.0147\n",
      "    142        \u001b[36m0.0942\u001b[0m  0.0123\n",
      "    143        \u001b[36m0.0940\u001b[0m  0.0141\n",
      "    144        \u001b[36m0.0930\u001b[0m  0.0122\n",
      "    145        \u001b[36m0.0907\u001b[0m  0.0156\n",
      "    146        \u001b[36m0.0905\u001b[0m  0.0178\n",
      "    147        \u001b[36m0.0884\u001b[0m  0.0103\n",
      "    148        \u001b[36m0.0879\u001b[0m  0.0140\n",
      "    149        \u001b[36m0.0862\u001b[0m  0.0142\n",
      "    150        \u001b[36m0.0850\u001b[0m  0.0160\n",
      "    151        \u001b[36m0.0843\u001b[0m  0.0148\n",
      "    152        \u001b[36m0.0827\u001b[0m  0.0148\n",
      "    153        \u001b[36m0.0819\u001b[0m  0.0119\n",
      "    154        \u001b[36m0.0807\u001b[0m  0.0189\n",
      "    155        \u001b[36m0.0800\u001b[0m  0.0120\n",
      "    156        \u001b[36m0.0789\u001b[0m  0.0155\n",
      "    157        \u001b[36m0.0777\u001b[0m  0.0174\n",
      "    158        \u001b[36m0.0764\u001b[0m  0.0113\n",
      "    159        \u001b[36m0.0757\u001b[0m  0.0139\n",
      "    160        \u001b[36m0.0754\u001b[0m  0.0182\n",
      "    161        \u001b[36m0.0738\u001b[0m  0.0132\n",
      "    162        \u001b[36m0.0735\u001b[0m  0.0140\n",
      "    163        \u001b[36m0.0721\u001b[0m  0.0132\n",
      "    164        \u001b[36m0.0716\u001b[0m  0.0128\n",
      "    165        \u001b[36m0.0699\u001b[0m  0.0171\n",
      "    166        \u001b[36m0.0692\u001b[0m  0.0141\n",
      "    167        \u001b[36m0.0676\u001b[0m  0.0184\n",
      "    168        \u001b[36m0.0670\u001b[0m  0.0168\n",
      "    169        \u001b[36m0.0662\u001b[0m  0.0162\n",
      "    170        \u001b[36m0.0656\u001b[0m  0.0193\n",
      "    171        \u001b[36m0.0646\u001b[0m  0.0171\n",
      "    172        \u001b[36m0.0635\u001b[0m  0.0144\n",
      "    173        \u001b[36m0.0630\u001b[0m  0.0143\n",
      "    174        \u001b[36m0.0622\u001b[0m  0.0135\n",
      "    175        \u001b[36m0.0614\u001b[0m  0.0126\n",
      "    176        \u001b[36m0.0602\u001b[0m  0.0150\n",
      "    177        \u001b[36m0.0597\u001b[0m  0.0147\n",
      "    178        \u001b[36m0.0588\u001b[0m  0.0206\n",
      "    179        \u001b[36m0.0587\u001b[0m  0.0147\n",
      "    180        \u001b[36m0.0574\u001b[0m  0.0174\n",
      "    181        \u001b[36m0.0566\u001b[0m  0.0168\n",
      "    182        0.0570  0.0127\n",
      "    183        \u001b[36m0.0561\u001b[0m  0.0165\n",
      "    184        \u001b[36m0.0549\u001b[0m  0.0133\n",
      "    185        \u001b[36m0.0544\u001b[0m  0.0175\n",
      "    186        \u001b[36m0.0532\u001b[0m  0.0160\n",
      "    187        0.0546  0.0166\n",
      "    188        \u001b[36m0.0528\u001b[0m  0.0144\n",
      "    189        0.0529  0.0133\n",
      "    190        0.0529  0.0138\n",
      "    191        \u001b[36m0.0509\u001b[0m  0.0137\n",
      "    192        \u001b[36m0.0503\u001b[0m  0.0129\n",
      "    193        \u001b[36m0.0487\u001b[0m  0.0141\n",
      "    194        \u001b[36m0.0483\u001b[0m  0.0162\n",
      "    195        \u001b[36m0.0480\u001b[0m  0.0150\n",
      "    196        \u001b[36m0.0470\u001b[0m  0.0163\n",
      "    197        0.0471  0.0150\n",
      "    198        \u001b[36m0.0460\u001b[0m  0.0143\n",
      "    199        \u001b[36m0.0457\u001b[0m  0.0252\n",
      "    200        0.0458  0.0183\n",
      "    201        \u001b[36m0.0451\u001b[0m  0.0311\n",
      "    202        \u001b[36m0.0446\u001b[0m  0.0242\n",
      "    203        \u001b[36m0.0436\u001b[0m  0.0159\n",
      "    204        \u001b[36m0.0433\u001b[0m  0.0135\n",
      "    205        \u001b[36m0.0428\u001b[0m  0.0138\n",
      "    206        \u001b[36m0.0419\u001b[0m  0.0131\n",
      "    207        \u001b[36m0.0419\u001b[0m  0.0134\n",
      "    208        \u001b[36m0.0413\u001b[0m  0.0130\n",
      "    209        \u001b[36m0.0406\u001b[0m  0.0199\n",
      "    210        \u001b[36m0.0405\u001b[0m  0.0120\n",
      "    211        \u001b[36m0.0402\u001b[0m  0.0161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    212        \u001b[36m0.0391\u001b[0m  0.0197\n",
      "    213        \u001b[36m0.0388\u001b[0m  0.0130\n",
      "    214        \u001b[36m0.0384\u001b[0m  0.0161\n",
      "    215        \u001b[36m0.0380\u001b[0m  0.0152\n",
      "    216        \u001b[36m0.0377\u001b[0m  0.0174\n",
      "    217        \u001b[36m0.0370\u001b[0m  0.0125\n",
      "    218        \u001b[36m0.0366\u001b[0m  0.0124\n",
      "    219        \u001b[36m0.0366\u001b[0m  0.0174\n",
      "    220        0.0367  0.0167\n",
      "    221        \u001b[36m0.0355\u001b[0m  0.0130\n",
      "    222        0.0358  0.0113\n",
      "    223        \u001b[36m0.0344\u001b[0m  0.0150\n",
      "    224        0.0348  0.0135\n",
      "    225        \u001b[36m0.0342\u001b[0m  0.0165\n",
      "    226        \u001b[36m0.0341\u001b[0m  0.0116\n",
      "    227        \u001b[36m0.0337\u001b[0m  0.0185\n",
      "    228        \u001b[36m0.0329\u001b[0m  0.0143\n",
      "    229        0.0333  0.0210\n",
      "    230        \u001b[36m0.0321\u001b[0m  0.0135\n",
      "    231        0.0324  0.0192\n",
      "    232        \u001b[36m0.0315\u001b[0m  0.0148\n",
      "    233        0.0326  0.0125\n",
      "    234        0.0332  0.0160\n",
      "    235        0.0320  0.0115\n",
      "    236        0.0324  0.0125\n",
      "    237        0.0317  0.0149\n",
      "    238        \u001b[36m0.0304\u001b[0m  0.0124\n",
      "    239        0.0306  0.0160\n",
      "    240        \u001b[36m0.0289\u001b[0m  0.0239\n",
      "    241        0.0302  0.0136\n",
      "    242        0.0303  0.0192\n",
      "    243        0.0291  0.0193\n",
      "    244        \u001b[36m0.0284\u001b[0m  0.0188\n",
      "    245        \u001b[36m0.0282\u001b[0m  0.0192\n",
      "    246        \u001b[36m0.0280\u001b[0m  0.0125\n",
      "    247        \u001b[36m0.0273\u001b[0m  0.0171\n",
      "    248        \u001b[36m0.0270\u001b[0m  0.0141\n",
      "    249        \u001b[36m0.0263\u001b[0m  0.0131\n",
      "    250        \u001b[36m0.0261\u001b[0m  0.0143\n",
      "    251        0.0263  0.0125\n",
      "    252        \u001b[36m0.0255\u001b[0m  0.0139\n",
      "    253        0.0260  0.0138\n",
      "    254        0.0259  0.0142\n",
      "    255        \u001b[36m0.0249\u001b[0m  0.0143\n",
      "    256        0.0250  0.0125\n",
      "    257        \u001b[36m0.0248\u001b[0m  0.0185\n",
      "    258        \u001b[36m0.0245\u001b[0m  0.0189\n",
      "    259        \u001b[36m0.0236\u001b[0m  0.0177\n",
      "    260        \u001b[36m0.0234\u001b[0m  0.0133\n",
      "    261        \u001b[36m0.0233\u001b[0m  0.0121\n",
      "    262        \u001b[36m0.0229\u001b[0m  0.0121\n",
      "    263        0.0229  0.0132\n",
      "    264        0.0229  0.0173\n",
      "    265        \u001b[36m0.0227\u001b[0m  0.0121\n",
      "    266        \u001b[36m0.0221\u001b[0m  0.0159\n",
      "    267        \u001b[36m0.0219\u001b[0m  0.0219\n",
      "    268        \u001b[36m0.0217\u001b[0m  0.0240\n",
      "    269        \u001b[36m0.0213\u001b[0m  0.0141\n",
      "    270        \u001b[36m0.0212\u001b[0m  0.0161\n",
      "    271        \u001b[36m0.0210\u001b[0m  0.0141\n",
      "    272        \u001b[36m0.0207\u001b[0m  0.0146\n",
      "    273        \u001b[36m0.0205\u001b[0m  0.0157\n",
      "    274        \u001b[36m0.0203\u001b[0m  0.0175\n",
      "    275        \u001b[36m0.0201\u001b[0m  0.0124\n",
      "    276        \u001b[36m0.0198\u001b[0m  0.0252\n",
      "    277        \u001b[36m0.0197\u001b[0m  0.0198\n",
      "    278        \u001b[36m0.0195\u001b[0m  0.0146\n",
      "    279        \u001b[36m0.0191\u001b[0m  0.0148\n",
      "    280        \u001b[36m0.0187\u001b[0m  0.0132\n",
      "    281        0.0194  0.0156\n",
      "    282        \u001b[36m0.0186\u001b[0m  0.0137\n",
      "    283        \u001b[36m0.0185\u001b[0m  0.0134\n",
      "    284        \u001b[36m0.0179\u001b[0m  0.0140\n",
      "    285        \u001b[36m0.0178\u001b[0m  0.0147\n",
      "    286        0.0178  0.0145\n",
      "    287        \u001b[36m0.0176\u001b[0m  0.0200\n",
      "    288        \u001b[36m0.0176\u001b[0m  0.0131\n",
      "    289        \u001b[36m0.0171\u001b[0m  0.0167\n",
      "    290        \u001b[36m0.0167\u001b[0m  0.0150\n",
      "    291        \u001b[36m0.0167\u001b[0m  0.0153\n",
      "    292        \u001b[36m0.0163\u001b[0m  0.0122\n",
      "    293        0.0164  0.0116\n",
      "    294        \u001b[36m0.0160\u001b[0m  0.0211\n",
      "    295        \u001b[36m0.0159\u001b[0m  0.0131\n",
      "    296        0.0161  0.0130\n",
      "    297        \u001b[36m0.0158\u001b[0m  0.0165\n",
      "    298        \u001b[36m0.0154\u001b[0m  0.0154\n",
      "    299        0.0155  0.0156\n",
      "    300        \u001b[36m0.0152\u001b[0m  0.0161\n",
      "    301        0.0153  0.0113\n",
      "    302        \u001b[36m0.0149\u001b[0m  0.0159\n",
      "    303        0.0151  0.0110\n",
      "    304        \u001b[36m0.0146\u001b[0m  0.0131\n",
      "    305        \u001b[36m0.0145\u001b[0m  0.0183\n",
      "    306        \u001b[36m0.0144\u001b[0m  0.0161\n",
      "    307        \u001b[36m0.0142\u001b[0m  0.0224\n",
      "    308        \u001b[36m0.0141\u001b[0m  0.0212\n",
      "    309        \u001b[36m0.0139\u001b[0m  0.0124\n",
      "    310        \u001b[36m0.0137\u001b[0m  0.0142\n",
      "    311        \u001b[36m0.0136\u001b[0m  0.0123\n",
      "    312        \u001b[36m0.0135\u001b[0m  0.0218\n",
      "    313        \u001b[36m0.0132\u001b[0m  0.0251\n",
      "    314        \u001b[36m0.0132\u001b[0m  0.0215\n",
      "    315        \u001b[36m0.0130\u001b[0m  0.0235\n",
      "    316        \u001b[36m0.0129\u001b[0m  0.0270\n",
      "    317        \u001b[36m0.0128\u001b[0m  0.0281\n",
      "    318        0.0129  0.0192\n",
      "    319        \u001b[36m0.0126\u001b[0m  0.0135\n",
      "    320        \u001b[36m0.0124\u001b[0m  0.0199\n",
      "    321        \u001b[36m0.0123\u001b[0m  0.0120\n",
      "    322        0.0124  0.0131\n",
      "    323        \u001b[36m0.0122\u001b[0m  0.0155\n",
      "    324        \u001b[36m0.0120\u001b[0m  0.0137\n",
      "    325        \u001b[36m0.0119\u001b[0m  0.0128\n",
      "    326        \u001b[36m0.0116\u001b[0m  0.0134\n",
      "    327        0.0117  0.0204\n",
      "    328        \u001b[36m0.0116\u001b[0m  0.0236\n",
      "    329        \u001b[36m0.0113\u001b[0m  0.0247\n",
      "    330        \u001b[36m0.0112\u001b[0m  0.0211\n",
      "    331        0.0113  0.0165\n",
      "    332        \u001b[36m0.0110\u001b[0m  0.0165\n",
      "    333        \u001b[36m0.0110\u001b[0m  0.0161\n",
      "    334        0.0112  0.0194\n",
      "    335        \u001b[36m0.0109\u001b[0m  0.0153\n",
      "    336        0.0109  0.0203\n",
      "    337        \u001b[36m0.0106\u001b[0m  0.0220\n",
      "    338        \u001b[36m0.0105\u001b[0m  0.0152\n",
      "    339        \u001b[36m0.0105\u001b[0m  0.0140\n",
      "    340        \u001b[36m0.0103\u001b[0m  0.0184\n",
      "    341        \u001b[36m0.0102\u001b[0m  0.0166\n",
      "    342        \u001b[36m0.0102\u001b[0m  0.0131\n",
      "    343        \u001b[36m0.0100\u001b[0m  0.0163\n",
      "    344        \u001b[36m0.0099\u001b[0m  0.0175\n",
      "    345        0.0100  0.0147\n",
      "    346        \u001b[36m0.0098\u001b[0m  0.0126\n",
      "    347        0.0098  0.0176\n",
      "    348        0.0098  0.0165\n",
      "    349        \u001b[36m0.0096\u001b[0m  0.0130\n",
      "    350        \u001b[36m0.0095\u001b[0m  0.0133\n",
      "    351        \u001b[36m0.0093\u001b[0m  0.0134\n",
      "    352        \u001b[36m0.0093\u001b[0m  0.0185\n",
      "    353        \u001b[36m0.0091\u001b[0m  0.0126\n",
      "    354        0.0092  0.0165\n",
      "    355        \u001b[36m0.0090\u001b[0m  0.0135\n",
      "    356        0.0091  0.0150\n",
      "    357        \u001b[36m0.0087\u001b[0m  0.0145\n",
      "    358        0.0088  0.0158\n",
      "    359        \u001b[36m0.0086\u001b[0m  0.0135\n",
      "    360        0.0088  0.0150\n",
      "    361        \u001b[36m0.0086\u001b[0m  0.0135\n",
      "    362        \u001b[36m0.0085\u001b[0m  0.0146\n",
      "    363        \u001b[36m0.0084\u001b[0m  0.0149\n",
      "    364        \u001b[36m0.0083\u001b[0m  0.0146\n",
      "    365        0.0083  0.0138\n",
      "    366        0.0083  0.0155\n",
      "    367        \u001b[36m0.0082\u001b[0m  0.0125\n",
      "    368        \u001b[36m0.0082\u001b[0m  0.0130\n",
      "    369        \u001b[36m0.0080\u001b[0m  0.0140\n",
      "    370        \u001b[36m0.0079\u001b[0m  0.0134\n",
      "    371        0.0080  0.0134\n",
      "    372        \u001b[36m0.0077\u001b[0m  0.0135\n",
      "    373        0.0078  0.0152\n",
      "    374        0.0078  0.0166\n",
      "    375        \u001b[36m0.0076\u001b[0m  0.0143\n",
      "    376        \u001b[36m0.0075\u001b[0m  0.0195\n",
      "    377        0.0076  0.0128\n",
      "    378        0.0075  0.0217\n",
      "    379        \u001b[36m0.0073\u001b[0m  0.0155\n",
      "    380        0.0073  0.0147\n",
      "    381        \u001b[36m0.0072\u001b[0m  0.0182\n",
      "    382        \u001b[36m0.0072\u001b[0m  0.0195\n",
      "    383        \u001b[36m0.0071\u001b[0m  0.0307\n",
      "    384        \u001b[36m0.0071\u001b[0m  0.0310\n",
      "    385        \u001b[36m0.0070\u001b[0m  0.0179\n",
      "    386        \u001b[36m0.0069\u001b[0m  0.0153\n",
      "    387        \u001b[36m0.0068\u001b[0m  0.0162\n",
      "    388        \u001b[36m0.0068\u001b[0m  0.0175\n",
      "    389        0.0068  0.0174\n",
      "    390        \u001b[36m0.0067\u001b[0m  0.0172\n",
      "    391        0.0070  0.0148\n",
      "    392        0.0070  0.0162\n",
      "    393        \u001b[36m0.0066\u001b[0m  0.0133\n",
      "    394        \u001b[36m0.0066\u001b[0m  0.0144\n",
      "    395        0.0066  0.0178\n",
      "    396        \u001b[36m0.0064\u001b[0m  0.0142\n",
      "    397        \u001b[36m0.0064\u001b[0m  0.0128\n",
      "    398        \u001b[36m0.0064\u001b[0m  0.0141\n",
      "    399        \u001b[36m0.0063\u001b[0m  0.0162\n",
      "    400        \u001b[36m0.0062\u001b[0m  0.0167\n",
      "\n",
      "âœ… Ensemble AUC: 0.6733\n",
      "âœ… Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.68      0.72       265\n",
      "           1       0.47      0.56      0.51       132\n",
      "\n",
      "    accuracy                           0.64       397\n",
      "   macro avg       0.61      0.62      0.61       397\n",
      "weighted avg       0.66      0.64      0.65       397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Imports ---\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# --- ANN Model ---\n",
    "class SimpleANN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.out = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.out(x)  # raw logits\n",
    "\n",
    "# --- Skorch ANN Wrapper ---\n",
    "net_ann = NeuralNetClassifier(\n",
    "    module=SimpleANN,\n",
    "    module__input_dim=X_train_scaled.shape[1],\n",
    "    max_epochs=400,\n",
    "    lr=0.001,\n",
    "    batch_size=128,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    criterion=nn.BCEWithLogitsLoss,\n",
    "    train_split=None,\n",
    "    iterator_train__shuffle=True,\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "# --- Train ANN ---\n",
    "X_train_np = X_train_scaled.astype(np.float32)\n",
    "y_train_np = y_train_res.values.astype(np.float32).reshape(-1, 1)\n",
    "net_ann.fit(X_train_np, y_train_np)\n",
    "\n",
    "# --- Extract the trained PyTorch model ---\n",
    "trained_model = net_ann.module_\n",
    "\n",
    "# --- Custom Wrapper (no skorch) ---\n",
    "class FrozenANN(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, torch_model):\n",
    "        self.torch_model = torch_model\n",
    "        self.torch_model.eval()  # set to eval mode\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self  # Do nothing\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        return (proba >= 0.5).astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X.astype(np.float32))\n",
    "            logits = self.torch_model(X_tensor)\n",
    "            probs = torch.sigmoid(logits).numpy()\n",
    "            probs = np.hstack([1 - probs, probs])  # shape (N, 2)\n",
    "        return probs\n",
    "\n",
    "# --- Wrap ANN ---\n",
    "wrapped_ann = FrozenANN(torch_model=trained_model)\n",
    "\n",
    "# --- Final Voting Classifier ---\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', best_rf),\n",
    "        ('xgb', best_xgb),\n",
    "        ('et', best_et),\n",
    "        ('ann', wrapped_ann)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# --- Fit tree models only ---\n",
    "ensemble.fit(X_train_np, y_train_res.values.ravel())\n",
    "\n",
    "# --- Evaluate ---\n",
    "X_val_np = X_val_scaled.astype(np.float32)\n",
    "y_pred_ens = ensemble.predict(X_val_np)\n",
    "y_proba_ens = ensemble.predict_proba(X_val_np)[:, 1]\n",
    "auc = roc_auc_score(y_val, y_proba_ens)\n",
    "\n",
    "print(f\"\\nâœ… Ensemble AUC: {auc:.4f}\")\n",
    "print(\"âœ… Classification Report:\\n\", classification_report(y_val, y_pred_ens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "395f0f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_bundle = {\n",
    "    'rf': best_rf,\n",
    "    'xgb': best_xgb,\n",
    "    'et': best_et,\n",
    "    'ann_state_dict': trained_model.state_dict(),\n",
    "    'ann_input_dim': X_train_scaled.shape[1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1134981c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../Models/SR-HSE/final_voting_classifier.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "\n",
    "joblib.dump(export_bundle, '../../Models/SR-HSE/final_voting_classifier.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
